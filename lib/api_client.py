"""
API communication and synchronization functions.
"""
import json
import requests

from lib.config import (
    logger,
    API_BASE_URL,
    READINGS_ENDPOINT,
    READINGS_BULK_ENDPOINT,
    API_HEADERS,
    BULK_SYNC_BATCH_SIZE,
    SELECT_UNSYNCED_SQL,
)
from lib.database import (
    get_local_db_connection,
    return_db_connection,
    save_to_backup,
)


def check_api_health():
    """Check if API server is reachable"""
    try:
        response = requests.get(f"{API_BASE_URL}/docs", timeout=5)
        if response.status_code == 200:
            logger.info(f"API server is reachable at {API_BASE_URL}")
            return True
    except requests.exceptions.RequestException as e:
        logger.warning(f"API server health check failed: {e}")
        return False


def insert_reading(device_id, ts_utc, json_data):
    """Send reading to API endpoint, fallback to local DB on failure"""
    try:
        # Parse JSON data if it's a string
        if isinstance(json_data, str):
            payload = json.loads(json_data)
        else:
            payload = json_data
        
        # Prepare the request payload according to API spec
        request_payload = {
            "device_id": device_id,
            "ts_utc": ts_utc.isoformat(),
            "payload": payload
        }
        
        # Send POST request to API
        response = requests.post(
            READINGS_ENDPOINT,
            json=request_payload,
            headers=API_HEADERS,
            timeout=10
        )
        
        if response.status_code == 201:
            logger.info(f"Reading successfully sent to API: {response.json()}")
            return True
        else:
            logger.error(f"API returned status {response.status_code}: {response.text}")
            # Fallback to backup database
            save_to_backup(device_id, ts_utc, json_data)
            return False
            
    except requests.exceptions.RequestException as e:
        logger.error(f"Failed to send reading to API: {e}")
        # Fallback to backup database
        save_to_backup(device_id, ts_utc, json_data)
        return False
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON payload: {e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error sending to API: {e}")
        # Fallback to backup database
        save_to_backup(device_id, ts_utc, json_data)
        return False


def sync_backup_to_api():
    """Periodically sync unsynced records from local backup to API using bulk upload"""
    import time
    
    while True:
        conn = None
        try:
            conn = get_local_db_connection()
            conn.autocommit = True
            cur = conn.cursor()
            
            # Fetch unsynced records from backup DB
            cur.execute(SELECT_UNSYNCED_SQL)
            records = cur.fetchall()
            
            if records:
                logger.info(f"Found {len(records)} unsynced records in backup database")
                
                # Process records in batches
                total_synced = 0
                for batch_start in range(0, len(records), BULK_SYNC_BATCH_SIZE):
                    batch_end = min(batch_start + BULK_SYNC_BATCH_SIZE, len(records))
                    batch = records[batch_start:batch_end]
                    
                    try:
                        # Prepare batch payload
                        batch_readings = []
                        batch_ids = []
                        
                        for record in batch:
                            record_id, dev_id, ts_utc, ts_local, payload = record
                            batch_ids.append(record_id)
                            
                            # Ensure payload is properly formatted
                            if isinstance(payload, dict):
                                payload_dict = payload
                            else:
                                payload_dict = json.loads(payload) if isinstance(payload, str) else {}
                            
                            # Don't include ts_local when syncing - it's auto-generated by the API
                            reading_entry = {
                                "device_id": dev_id,
                                "ts_utc": ts_utc.isoformat() if hasattr(ts_utc, 'isoformat') else ts_utc,
                                "payload": payload_dict
                            }
                            batch_readings.append(reading_entry)
                        
                        # Send batch to API
                        bulk_payload = {"readings": batch_readings}
                        response = requests.post(
                            READINGS_BULK_ENDPOINT,
                            json=bulk_payload,
                            headers=API_HEADERS,
                            timeout=30  # Allow longer timeout for bulk uploads
                        )
                        
                        if response.status_code == 201:
                            response_data = response.json()
                            created_count = response_data.get("created", 0)
                            logger.info(f"Bulk synced {created_count} records to API (batch {batch_start // BULK_SYNC_BATCH_SIZE + 1})")
                            
                            # Delete successfully uploaded records from local DB
                            try:
                                placeholders = ','.join(['%s'] * len(batch_ids))
                                delete_batch_sql = f"DELETE FROM sensor_project.readings WHERE id IN ({placeholders})"
                                cur.execute(delete_batch_sql, batch_ids)
                                logger.info(f"Deleted {len(batch_ids)} synced records from backup database")
                                total_synced += len(batch_ids)
                            except Exception as e:
                                logger.error(f"Failed to delete synced records: {e}")
                        else:
                            logger.warning(f"Failed to sync batch: API returned {response.status_code} - {response.text}")
                            
                    except Exception as e:
                        logger.error(f"Failed to sync batch: {e}")
                
                if total_synced > 0:
                    logger.info(f"Successfully synced {total_synced} total records to API")
            
            cur.close()
            
        except Exception as e:
            logger.error(f"Backup sync to API failed: {e}")
        finally:
            if conn:
                return_db_connection(conn)
        
        # Wait before next sync attempt
        time.sleep(5)
